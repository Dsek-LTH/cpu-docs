# ğŸš¨ 2025-03-21

### ğŸ“‹ Overview

| Incident | All services unavailable |
|----|----|
| Severity | Critical |
| Affected services | All services |
| Duration | March 21, 2025 1:50 until March 16, 2025 07:40 |
| Responders | @[Isak Kallini](mention://9d13a341-c3fd-4ff2-afea-190e23d334e4/user/6a2498b2-e61e-4c71-9755-6d7ff90efab3) @[David Agardh](mention://4363eee1-b4b6-414a-961b-cbefba05b639/user/b7aca933-2918-4648-8de7-a9692cd6e477)   |

### â±ï¸ Incident timeline

* 01:51 â€” Report in #status-alerts that multiple services are down
* 07:31 â€” Thread created in #cpu-allmÃ¤nt
* 07:35 â€” Manual startup of docker, mailmaster motion-generator and snejk
* 07:35 â€” Manual restart of pm2 on web-beta

### â›‘ï¸ Postmortem report

* âš ï¸ Leadup

  Around 01:46, something causes pando to reboot. The oVirt nodes begin logging errors because the nfs mounts are unreachable. A few minutes later, two of the oVirt nodes reboot, but not lavender. Pando comes back at 02:00 and nfs mounts are available again. Some VMs restart automatically, but not all.
* ğŸ¤·â€â™€ï¸ Fault

  !!Describe what didn't work as expected!!
* ğŸ¥ Impact

  !!Describe how users where impacted during the incident. Include how many support cases were raised.!!
* ğŸ‘ï¸ Detection

  System monitoring detected the outage immediately.
* ğŸ” Root cause

  !!Run a 5-whys analysis to understand the true causes of the incident. Begin with a description of the impact and ask why it occurred. Continue asking "why" until you arrive at a root cause!!.
* ğŸ—ƒï¸ Related records

  !!Check if any past incidents could've had the same root cause. Ask why this incident occured again.!!
* ğŸ¤” Lessons learned

  !!Describe what you learned, what went well, and how you can improve.!!

### âœ… Follow-up tasks

List the issues created to prevent this class of incident in the future.

| Issue | Owner | Todo | Links |
|----|----|----|----|
|    |    |    |    |
|    |    |    |    |
|    |    |    |    |